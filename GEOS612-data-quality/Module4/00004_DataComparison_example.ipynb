{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Comparison.\n",
    "\n",
    "1. This notebook illustrates how to compare data values with matching timestamps for science variables from two data delivery methods of a CTD (Conductivity Temperature Depth) sensor deployed on a Global Papa Station in the Northern Pacific Ocean (sensor reference designator: GP03FLMB-RIM01-02-CTDMOG060). \n",
    "\n",
    "Click on the [Link](https://drive.google.com/open?id=1_kAzdVfou_PWG-UnwB7Nib4NpyktKsVg) for more information about the station.\n",
    "\n",
    "**Missing Data Test:**\n",
    "<blockquote>  Provides the number of gaps and days of data that are missing in the \"preferred\" dataset delivery method and are available in a \"non-preferred\" dataset delivery method. </blockquote> \n",
    "\n",
    "**Data Comparison:** \n",
    "<blockquote> Compare data values with matching timestamps for science variables among all delivery methods.</blockquote> \n",
    "\n",
    "We will be using two keywords for data delivery methods in this example:\n",
    "- <font color=\"red\"> recovered: </font>  data collected after the instrument was recovered from the water. This is the preferred data delivery method because it is expected to be the most complete.\n",
    "\n",
    "- <font color=\"red\"> telemetered: </font> data transmitted via a telemetry system while the instrument is in the water. This is the non-preferred data delivery method because it is less complete (not all data are transmitted via telemetry. The files are subsampled for the telemetry system to work)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline:\n",
    "- [Python Packages.](#1)\n",
    "- [Data File.](#2)\n",
    "    - [Telemetered Data Files.](#21)\n",
    "    - [ Recovered Data Files.](#22)\n",
    "- [Define Functions.](#3)\n",
    "- [Data Comparison.](#4)\n",
    "    - [Selected Datasets for Comparison.](#41)\n",
    "    - [Load recovered Dataset.](#42)\n",
    "    - [Load telemetered Dataset.](#43)\n",
    "    - [Map Parameters from the Two Files.](#44)\n",
    "    - [View files data comparison result:](#45)\n",
    "- [Observations.](#5)\n",
    "- [Summary.](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Orange' size=20 > **Attention:** </span> \n",
    "- To run the notebook, you need to follow the septs in order.\n",
    "- For the code cell, run the cell before you move on to the next one. \n",
    "    - **Remember**: The output of a cell may be an input in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\" ></a>\n",
    "### Python Packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\" ></a>\n",
    "### Data File.\n",
    "\n",
    "- Get the list of files from all data delivery methods. Two .csv files are used for this example:\n",
    "\n",
    "         *_recovered.csv   &  *_telemetered.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leilabelabassi/Desktop/TAMU/online-class/612-DataQuality4theGeosciences/class_material/Module4_csvFiles\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/leilabelabassi/Desktop/TAMU/online-class/612-DataQuality4theGeosciences/class_material/Module4_csvFiles/'\n",
    "\n",
    "file_recovered = 'data_review_list_GP03FLMB-RIM01-02-CTDMOG060_recovered.csv'\n",
    "list_recovered = pd.read_csv(file_recovered)\n",
    "\n",
    "file_telemetered = 'data_review_list_GP03FLMB-RIM01-02-CTDMOG060_telemetered.csv'\n",
    "list_telemetered = pd.read_csv(file_telemetered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"21\" ></a>\n",
    "#### Telemetered Data Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deployment0001_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20130724T100001-20140227T140001.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deployment0002_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20140620T040001-20141109T000001.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deployment0003_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20150609T000001-20160209T220001.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deployment0004_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20161008T080001-20161219T000001.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deployment0007_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20190928T000001-20200118T200001.nc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      files\n",
       "0  deployment0001_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20130724T100001-20140227T140001.nc\n",
       "1  deployment0002_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20140620T040001-20141109T000001.nc\n",
       "2  deployment0003_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20150609T000001-20160209T220001.nc\n",
       "3  deployment0004_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20161008T080001-20161219T000001.nc\n",
       "4  deployment0007_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20190928T000001-20200118T200001.nc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the list of files for the telemetered data delivery method\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "(list_telemetered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"22\" ></a>\n",
    "#### Recovered Data Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deployment0001_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20130724T064501-20140617T234501.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deployment0003_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20150608T213001-20160703T183001.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deployment0004_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20160704T231501-20170717T150001.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deployment0005_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20170714T230001-20180725T170001.nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deployment0006_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20180724T231501-20190927T234501.nc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          files\n",
       "0  deployment0001_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20130724T064501-20140617T234501.nc\n",
       "1  deployment0003_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20150608T213001-20160703T183001.nc\n",
       "2  deployment0004_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20160704T231501-20170717T150001.nc\n",
       "3  deployment0005_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20170714T230001-20180725T170001.nc\n",
       "4  deployment0006_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20180724T231501-20190927T234501.nc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the list of files for the recovered data delivery method\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "list_recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\" ></a>\n",
    "### Define Functions.\n",
    "- The functions are created to divide the process into defined steps that can be called separately to execute a specific data quality module.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_science_vars(stream):\n",
    "    \"\"\"\n",
    "    Returns data parameters with scientific units relevent ocean processes.\n",
    "    Source URL:\n",
    "    http://datareview.marine.rutgers.edu/streams/view/ctdmo_ghqr_instrument_recovered.json\n",
    "    \"\"\"\n",
    "    sci_vars = []\n",
    "    dr = 'http://datareview.marine.rutgers.edu/streams/view/{}.json'.format(stream)\n",
    "    r = requests.get(dr)\n",
    "    params = r.json()['stream']['parameters']\n",
    "    for p in params:\n",
    "        if p['data_product_type'] == 'Science Data':\n",
    "            sci_vars.append(p['name'])\n",
    "    return sci_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_names(dataset, vars):\n",
    "    \"\"\"\n",
    "    Returns the long names for the science data parameters.\n",
    "    Long names are used to match parameters from two delivery methods. \n",
    "    \"\"\"\n",
    "    name = []\n",
    "    long_name = []\n",
    "    for v in vars:\n",
    "        name.append(v)\n",
    "        try:\n",
    "            longname = dataset[v].long_name\n",
    "        except AttributeError:\n",
    "            longname = vars\n",
    "        long_name.append(longname)\n",
    "\n",
    "    return pd.DataFrame({'name': name, 'long_name': long_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_units(variable):\n",
    "    \"\"\"\n",
    "    Returns units for science data parameters.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y_units = variable.units\n",
    "    except AttributeError:\n",
    "        y_units = 'no_units'\n",
    "\n",
    "    return y_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_variable_info(dataset, variable_name, rename):\n",
    "    \"\"\"\n",
    "    Returns the parameter's data and time array.\n",
    "    Returns the parameter's unit using var_units function.\n",
    "    Returns the count of nans in the parameter's data array.\n",
    "    \"\"\"\n",
    "    ds_units = var_units(dataset[variable_name])\n",
    "\n",
    "    ds_df = pd.DataFrame({'time': dataset['time'].values, variable_name: dataset[variable_name].values})\n",
    "    ds_df.rename(columns={str(variable_name): rename}, inplace=True)\n",
    "    n = len(ds_df[rename])\n",
    "    n_nan = sum(ds_df[rename].isnull())\n",
    "\n",
    "    # round to the nearest second\n",
    "    ds_df['time'] = ds_df['time'].map(lambda t: t.replace(microsecond=0) + timedelta(seconds=(round(t.microsecond / 1000000.0))))\n",
    "\n",
    "    return [ds_df, ds_units, n, n_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_times(df):\n",
    "    '''\n",
    "    Compares two delivery methods and returns a dictionary with information about missing data:\n",
    "    - time ranges   - number of data points   - number of days.\n",
    "    Skips gaps that are only 1 data point (or one hour if data are rounded to the hour).\n",
    "    '''\n",
    "   \n",
    "    md_list = []\n",
    "    n_list = []\n",
    "    mdays = []\n",
    "    index_break = []\n",
    "    ilist = df.index.tolist()\n",
    "\n",
    "    if len(ilist) == 1:\n",
    "        ii = ilist[0]\n",
    "        md_list.append(pd.to_datetime(str(df['time'][ii])).strftime('%Y-%m-%dT%H:%M:%S'))\n",
    "        n_list.append(1)\n",
    "    else:\n",
    "        for i, n in enumerate(ilist):\n",
    "            if i == 0:\n",
    "                index_break.append(ilist[i])\n",
    "            elif i == (len(ilist) - 1):\n",
    "                index_break.append(ilist[i])\n",
    "            else:\n",
    "                if (n - ilist[i-1]) > 1:\n",
    "                    index_break.append(ilist[i-1])\n",
    "                    index_break.append(ilist[i])\n",
    "\n",
    "        for ii, nn in enumerate(index_break):\n",
    "            if ii % 2 == 0:  # check that the index is an even number\n",
    "                if index_break[ii + 1] != nn:  # only list gaps that are more than 1 data point\n",
    "                    try:\n",
    "                        # create a list of timestamps for each gap to get the unique # of days missing from one dataset\n",
    "                        time_lst = [df['time'][t].date() for t in range(nn, index_break[ii + 1] + 1)]\n",
    "                    except KeyError:  # if the last data gap is only 1 point, skip\n",
    "                        continue\n",
    "                    md_list.append([pd.to_datetime(str(df['time'][nn])).strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "                                    pd.to_datetime(str(df['time'][index_break[ii + 1]])).strftime('%Y-%m-%dT%H:%M:%S')])\n",
    "                    n_list.append(index_break[ii + 1] - nn + 1)\n",
    "                    mdays.append(len(np.unique(time_lst)))\n",
    "\n",
    "    n_total = sum(n_list)\n",
    "    n_days = sum(mdays)\n",
    "\n",
    "    return dict(missing_data_gaps=md_list, n_missing=n_list, n_missing_total=n_total, n_missing_days_total=n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_timestamps_hour(ds):\n",
    "    # returns dataframe of unique timestamps rounded to the nearest hour\n",
    "    df = pd.DataFrame(ds['time'].values, columns=['time'])\n",
    "    df = df['time'].map(lambda t: t.replace(second=0, microsecond=0, nanosecond=0, minute=0, hour=t.hour) + timedelta(hours=t.minute // 30))\n",
    "    udf = pd.DataFrame(np.unique(df), columns=['time'])\n",
    "\n",
    "    return udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\"> Attention: </font> The data comparison process is created as a function (**compare_datasets**) so it can be used with any two data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets(mapping, preferred_method, deployment, ds0, method0, ds1, method1):\n",
    "    '''\n",
    "    returns parameter's unit_test, number of nan, missing data status, \n",
    "    number of data points compared,\n",
    "    min and max of absolute differences,\n",
    "    number of data points with a difference greater than 0.9999999999999999, \n",
    "    percent of data points with a difference greater than 0.9999999999999999.\n",
    "    '''\n",
    "    \n",
    "    # Initialize Variables\n",
    "    df =  pd.DataFrame()\n",
    "    missing_data_list = []\n",
    "    diff_gzero_list = []\n",
    "    var_list = []\n",
    "    blank_dict = {'missing_data_gaps': [], 'n_missing': [], 'n_missing_days_total': 0,\n",
    "                                          'n_missing_total': 0}\n",
    "    for rr in mapping.itertuples():\n",
    "        index, name, long_name_x, long_name_y = rr\n",
    "\n",
    "        ds0_rename = '_'.join((str(name), 'ds0'))\n",
    "        [ds0_df, ds0_units, n0, n0_nan] = get_ds_variable_info(ds0, name, ds0_rename)\n",
    "        ds1_rename = '_'.join((str(name), 'ds1'))\n",
    "        [ds1_df, ds1_units, n1, n1_nan] = get_ds_variable_info(ds1, name, ds1_rename)\n",
    "              \n",
    "        # Compare units\n",
    "        if ds0_units == ds1_units:\n",
    "            unit_test = 'pass'\n",
    "        else:\n",
    "            unit_test = 'fail'\n",
    "\n",
    "        # Merge dataframes from both methods\n",
    "        merged = pd.merge(ds0_df, ds1_df, on='time', how='outer')\n",
    "\n",
    "        # Drop rows where both variables are NaNs, and make sure the timestamps are in order\n",
    "        merged.dropna(subset=[ds0_rename, ds1_rename], how='all', inplace=True)\n",
    "\n",
    "        if len(merged) == 0:\n",
    "            print('No valid data to compare')\n",
    "            n_comparison = 0\n",
    "            n_diff_g_zero = None\n",
    "            min_diff = None\n",
    "            max_diff = None\n",
    "            ds0_missing_dict = 'No valid data to compare'\n",
    "            ds1_missing_dict = 'No valid data to compare'\n",
    "        else:\n",
    "            merged = merged.sort_values('time').reset_index(drop=True)\n",
    "            m_intersect = merged[merged[ds0_rename].notnull() & merged[ds1_rename].notnull()]\n",
    "\n",
    "            # If the number of data points for comparison is less than 1% of the smaller sample size\n",
    "            # compare the timestamps by rounding to the nearest hour\n",
    "            if len(m_intersect) == 0 or float(len(m_intersect))/float(min(n0, n1))*100 < 1.00:\n",
    "                n_comparison = 0\n",
    "                n_diff_g_zero = None\n",
    "                min_diff = None\n",
    "                max_diff = None\n",
    "\n",
    "                utime_df0 = unique_timestamps_hour(ds0)\n",
    "                utime_df0['ds0'] = 'ds0'\n",
    "                utime_df1 = unique_timestamps_hour(ds1)\n",
    "                utime_df1['ds1'] = 'ds1'\n",
    "                umerged = pd.merge(utime_df0, utime_df1, on='time', how='outer')\n",
    "                umerged = umerged.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "                if 'telemetered' in method0:\n",
    "                    ds0_missing_dict = 'method not checked for missing data'\n",
    "                else:\n",
    "                    ds0_missing = umerged.loc[umerged['ds0'].isnull()]\n",
    "                    if len(ds0_missing) > 0:\n",
    "                        ds0_missing_dict = missing_data_times(ds0_missing)\n",
    "                        if ds0_missing_dict != blank_dict:\n",
    "                            ds0_missing_dict['n_hours_missing'] = ds0_missing_dict.pop('n_missing')\n",
    "                            ds0_missing_dict['n_hours_missing_total'] = ds0_missing_dict.pop('n_missing_total')\n",
    "                        else:\n",
    "                            ds0_missing_dict = 'timestamps rounded to the hour: no missing data'\n",
    "                    else:\n",
    "                        ds0_missing_dict = 'timestamps rounded to the hour: no missing data'\n",
    "\n",
    "                if 'telemetered' in method1:\n",
    "                    ds1_missing_dict = 'method not checked for missing data'\n",
    "                else:\n",
    "                    ds1_missing = umerged.loc[umerged['ds1'].isnull()]\n",
    "                    if len(ds1_missing) > 0:\n",
    "                        ds1_missing_dict = missing_data_times(ds1_missing)\n",
    "                        if ds1_missing_dict != blank_dict:\n",
    "                            ds1_missing_dict['n_hours_missing'] = ds1_missing_dict.pop('n_missing')\n",
    "                            ds1_missing_dict['n_hours_missing_total'] = ds1_missing_dict.pop('n_missing_total')\n",
    "                        else:\n",
    "                            ds1_missing_dict = 'timestamps rounded to the hour: no missing data'\n",
    "                    else:\n",
    "                        ds1_missing_dict = 'timestamps rounded to the hour: no missing data'\n",
    "\n",
    "            else:\n",
    "                # Find where data are available in one dataset and missing in the other if\n",
    "                # timestamps match exactly. Don't check for missing data in telemetered\n",
    "                # datasets.\n",
    "                if 'telemetered' in method0:\n",
    "                    ds0_missing_dict = 'method not checked for missing data'\n",
    "                else:\n",
    "                    ds0_missing = merged.loc[merged[ds0_rename].isnull()]\n",
    "                    if len(ds0_missing) > 0:\n",
    "                        ds0_missing_dict = missing_data_times(ds0_missing)\n",
    "                        if ds0_missing_dict == blank_dict:\n",
    "                            ds0_missing_dict = 'no missing data'\n",
    "                    else:\n",
    "                        ds0_missing_dict = 'no missing data'\n",
    "\n",
    "                if 'telemetered' in method1:\n",
    "                    ds1_missing_dict = 'method not checked for missing data'\n",
    "                else:\n",
    "                    ds1_missing = merged.loc[merged[ds1_rename].isnull()]\n",
    "                    if len(ds1_missing) > 0:\n",
    "                        ds1_missing_dict = missing_data_times(ds1_missing)\n",
    "                        if ds1_missing_dict == blank_dict:\n",
    "                            ds1_missing_dict = 'no missing data'\n",
    "                    else:\n",
    "                        ds1_missing_dict = 'no missing data'\n",
    "\n",
    "                # Where the data intersect, calculate the difference between the methods\n",
    "                diff = m_intersect[ds0_rename] - m_intersect[ds1_rename]\n",
    "                n_diff_g_zero = sum(abs(diff) > 0.99999999999999999)\n",
    "\n",
    "                min_diff = round(min(abs(diff)), 10)\n",
    "                max_diff = round(max(abs(diff)), 10)\n",
    "                n_comparison = len(diff)\n",
    "          \n",
    "        compare_summary = dict( \n",
    "                                ds0=dict(name=ds0_rename, units=ds0_units, n=n0, n_nan=n0_nan, missing=ds0_missing_dict),\n",
    "                                ds1=dict(name=ds1_rename, units=ds1_units, n=n1, n_nan=n1_nan, missing=ds1_missing_dict),\n",
    "                                unit_test=unit_test, n_comparison=n_comparison, n_diff_greater_zero=n_diff_g_zero,\n",
    "                                min_abs_diff=min_diff, max_abs_diff=max_diff\n",
    "                              )\n",
    "        \n",
    "        name = compare_summary[preferred_method]['name']\n",
    "        units = compare_summary[preferred_method]['units']\n",
    "        unit_test = compare_summary['unit_test']\n",
    "        n = compare_summary[preferred_method]['n']\n",
    "        n_nan = compare_summary[preferred_method]['n_nan']\n",
    "        missing_data = compare_summary[preferred_method]['missing']\n",
    "        n_comparison = compare_summary['n_comparison']\n",
    "        min_abs_diff = compare_summary['min_abs_diff']\n",
    "        max_abs_diff = compare_summary['max_abs_diff']\n",
    "        n_diff_greater_zero = compare_summary['n_diff_greater_zero']\n",
    "        \n",
    "        if n_comparison > 0:\n",
    "            percent_diff_greater_zero = round((float(n_diff_greater_zero)/float(n_comparison) * 100), 2)\n",
    "        else:\n",
    "            percent_diff_greater_zero = None\n",
    "\n",
    "        missing_data_list.append(str(missing_data))\n",
    "        diff_gzero_list.append(percent_diff_greater_zero)\n",
    "        var_list.append(name) \n",
    "\n",
    "        df0 = pd.DataFrame({\n",
    "                            'parameter':[name], \n",
    "                            'unit': [units], \n",
    "                            'unit_test': [unit_test], \n",
    "                            'n': [n] ,\n",
    "                            'n_nan': [n_nan] ,\n",
    "                            'missing_data': [missing_data], \n",
    "                            'n_comparison': [n_comparison], \n",
    "                            'min_abs_diff': [min_abs_diff], \n",
    "                            'max_abs_diff': [max_abs_diff],\n",
    "                            'n_diff_greater_0.99': [n_diff_greater_zero], \n",
    "                            'percent_diff_greater_zero': [percent_diff_greater_zero]},\n",
    "                            index= [deployment])\n",
    "        df = df.append(df0)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\" ></a>\n",
    "### Data Comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected Datasets for Comparison.\n",
    "For this example, we are comparing deployment 1 telemetered and recovered data.\n",
    "The attributes needed for this comparison exist in the file name:\n",
    "\n",
    "<span style='color:blue'>Deployment number</span>: deployment**0001**_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20130724T064501-20140617T234501.nc\n",
    "\n",
    "<span style='color:blue'>Sensor Reference Designator </span>: deployment0001_**GP03FLMB-RIM01-02-CTDMOG060**-recovered_inst-ctdmo_ghqr_instrument_recovered_20130724T064501-20140617T234501.nc\n",
    "\n",
    "<span style='color:blue'>Data Delivery Method</span>: deployment0001_GP03FLMB-RIM01-02-CTDMOG060-**recovered_inst**-ctdmo_ghqr_instrument_recovered_20130724T064501-20140617T234501.nc\n",
    "\n",
    "<span style='color:blue'>Data Stream</span>: deployment0001_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-**ctdmo_ghqr_instrument_recovered**_20130724T064501-20140617T234501.nc\n",
    "\n",
    "<span style='color:blue'>Data Time Coverage</span>: deployment0001_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_**20130724T064501-20140617T234501**.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"41\" ></a>\n",
    "#### Load recovered Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leilabelabassi/Desktop/TAMU/online-class/612-DataQuality4theGeosciences/class_material/Module3_DataFiles_recovered-GP03FLMB-RIM01-02-CTDMOG060\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/leilabelabassi/Desktop/TAMU/online-class/612-DataQuality4theGeosciences/class_material/Module3_DataFiles_recovered-GP03FLMB-RIM01-02-CTDMOG060'\n",
    "# Load data\n",
    "ds0 = xr.open_dataset('deployment0001_GP03FLMB-RIM01-02-CTDMOG060-recovered_inst-ctdmo_ghqr_instrument_recovered_20130724T064501-20140617T234501.nc')\n",
    "\n",
    "# data delivery method (copied from the file name):\n",
    "method0 = 'recovered_inst'\n",
    "\n",
    "# data stream for recoverd data delivery method (copied from the file name):\n",
    "stream0 = 'ctdmo_ghqr_instrument_recovered'\n",
    "\n",
    "# The preferred data recovery method for the oceanographic instrument used in this example \n",
    "# is always recovered. Telemetered data have less data. Here the string 'ds0' is used to reference to recovered data.\n",
    "preferred_method = 'ds0' \n",
    "                         \n",
    "# deployment number (copied from the file name):\n",
    "deployment = '1'\n",
    "\n",
    "\n",
    "# Get list of science parameters\n",
    "sci_var0 = return_science_vars(stream0) \n",
    "long_name0 = long_names(ds0, sci_var0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['density',\n",
       " 'practical_salinity',\n",
       " 'ctdmo_seawater_pressure',\n",
       " 'ctdmo_seawater_temperature',\n",
       " 'ctdmo_seawater_conductivity']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_var0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"42\" ></a>\n",
    "#### Load telemetered Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leilabelabassi/Desktop/TAMU/online-class/612-DataQuality4theGeosciences/class_material/Module3_DataFiles_telemetered-GP03FLMB-RIM01-02-CTDMOG060\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/leilabelabassi/Desktop/TAMU/online-class/612-DataQuality4theGeosciences/class_material/Module3_DataFiles_telemetered-GP03FLMB-RIM01-02-CTDMOG060/'\n",
    "\n",
    "# Load data\n",
    "ds1 = xr.open_dataset('deployment0001_GP03FLMB-RIM01-02-CTDMOG060-telemetered-ctdmo_ghqr_sio_mule_instrument_20130724T100001-20140227T140001.nc')\n",
    " \n",
    "method1 = 'telemetered'\n",
    "stream1 = 'ctdmo_ghqr_sio_mule_instrument'\n",
    "\n",
    "# Get list of science parameters\n",
    "sci_var1 = return_science_vars(stream1) \n",
    "long_name1 = long_names(ds1, sci_var1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>long_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>density</td>\n",
       "      <td>Seawater Density</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>practical_salinity</td>\n",
       "      <td>Practical Salinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctdmo_seawater_pressure</td>\n",
       "      <td>Seawater Pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ctdmo_seawater_temperature</td>\n",
       "      <td>Seawater Temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctdmo_seawater_conductivity</td>\n",
       "      <td>Seawater Conductivity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name              long_name\n",
       "0                      density       Seawater Density\n",
       "1           practical_salinity     Practical Salinity\n",
       "2      ctdmo_seawater_pressure      Seawater Pressure\n",
       "3   ctdmo_seawater_temperature   Seawater Temperature\n",
       "4  ctdmo_seawater_conductivity  Seawater Conductivity"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_name1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"43\" ></a>\n",
    "#### Map Parameters from the Two Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>long_name_x</th>\n",
       "      <th>long_name_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>density</td>\n",
       "      <td>Seawater Density</td>\n",
       "      <td>Seawater Density</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>practical_salinity</td>\n",
       "      <td>Practical Salinity</td>\n",
       "      <td>Practical Salinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctdmo_seawater_pressure</td>\n",
       "      <td>Seawater Pressure</td>\n",
       "      <td>Seawater Pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ctdmo_seawater_temperature</td>\n",
       "      <td>Seawater Temperature</td>\n",
       "      <td>Seawater Temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctdmo_seawater_conductivity</td>\n",
       "      <td>Seawater Conductivity</td>\n",
       "      <td>Seawater Conductivity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name            long_name_x            long_name_y\n",
       "0                      density       Seawater Density       Seawater Density\n",
       "1           practical_salinity     Practical Salinity     Practical Salinity\n",
       "2      ctdmo_seawater_pressure      Seawater Pressure      Seawater Pressure\n",
       "3   ctdmo_seawater_temperature   Seawater Temperature   Seawater Temperature\n",
       "4  ctdmo_seawater_conductivity  Seawater Conductivity  Seawater Conductivity"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.merge(long_name0, long_name1, on='name', how='inner')\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"44\" ></a>\n",
    "#### Run Data Comparison for the Slected Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function and run it.\n",
    "df = compare_datasets(mapping, preferred_method, deployment, ds0, method0, ds1, method1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"45\" ></a>\n",
    "#### View files data comparison result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_test</th>\n",
       "      <th>n</th>\n",
       "      <th>n_nan</th>\n",
       "      <th>missing_data</th>\n",
       "      <th>n_comparison</th>\n",
       "      <th>min_abs_diff</th>\n",
       "      <th>max_abs_diff</th>\n",
       "      <th>n_diff_greater_0.99</th>\n",
       "      <th>percent_diff_greater_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>density_ds0</td>\n",
       "      <td>kg m-3</td>\n",
       "      <td>pass</td>\n",
       "      <td>31557</td>\n",
       "      <td>0</td>\n",
       "      <td>no missing data</td>\n",
       "      <td>2539</td>\n",
       "      <td>8.400000e-09</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>practical_salinity_ds0</td>\n",
       "      <td>1</td>\n",
       "      <td>pass</td>\n",
       "      <td>31557</td>\n",
       "      <td>0</td>\n",
       "      <td>no missing data</td>\n",
       "      <td>2539</td>\n",
       "      <td>5.510000e-08</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ctdmo_seawater_pressure_ds0</td>\n",
       "      <td>dbar</td>\n",
       "      <td>pass</td>\n",
       "      <td>31557</td>\n",
       "      <td>0</td>\n",
       "      <td>no missing data</td>\n",
       "      <td>2539</td>\n",
       "      <td>2.783384e-03</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ctdmo_seawater_temperature_ds0</td>\n",
       "      <td>ºC</td>\n",
       "      <td>pass</td>\n",
       "      <td>31557</td>\n",
       "      <td>0</td>\n",
       "      <td>no missing data</td>\n",
       "      <td>2539</td>\n",
       "      <td>1.200000e-08</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ctdmo_seawater_conductivity_ds0</td>\n",
       "      <td>S m-1</td>\n",
       "      <td>pass</td>\n",
       "      <td>31557</td>\n",
       "      <td>0</td>\n",
       "      <td>no missing data</td>\n",
       "      <td>2539</td>\n",
       "      <td>1.200000e-09</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         parameter    unit unit_test      n  n_nan  \\\n",
       "1                      density_ds0  kg m-3      pass  31557      0   \n",
       "1           practical_salinity_ds0       1      pass  31557      0   \n",
       "1      ctdmo_seawater_pressure_ds0    dbar      pass  31557      0   \n",
       "1   ctdmo_seawater_temperature_ds0      ºC      pass  31557      0   \n",
       "1  ctdmo_seawater_conductivity_ds0   S m-1      pass  31557      0   \n",
       "\n",
       "      missing_data  n_comparison  min_abs_diff  max_abs_diff  \\\n",
       "1  no missing data          2539  8.400000e-09      0.000187   \n",
       "1  no missing data          2539  5.510000e-08      0.000141   \n",
       "1  no missing data          2539  2.783384e-03      0.020546   \n",
       "1  no missing data          2539  1.200000e-08      0.000117   \n",
       "1  no missing data          2539  1.200000e-09      0.000007   \n",
       "\n",
       "   n_diff_greater_0.99  percent_diff_greater_zero  \n",
       "1                    0                        0.0  \n",
       "1                    0                        0.0  \n",
       "1                    0                        0.0  \n",
       "1                    0                        0.0  \n",
       "1                    0                        0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\" ></a>\n",
    "### Observations:\n",
    "- Parameters: The returned science parameters in the file are:  conductivity, temperature, pressure, salinty, and density.     \n",
    "- Unit Test: Both recovered and telemetered files share the same units for the same parameters.  \n",
    "- Nans: The are no nans in both files.\n",
    "- Missing data: There are no data missing from the recovered data file when compared to telemetered data.  \n",
    "- Value Difference: \n",
    "    - min and max absolute difference is not null but close to zero.\n",
    "    - The number of data points with difference greater than 0.99 is zero. \n",
    "    - The percent of data points with difference greater than 0.99 is zero.\n",
    "<a id=\"6\" ></a>    \n",
    " ### Summary  \n",
    "The data from recovered and telemetered data are consistent, which increase our confidence with the data. Some of the difference although not significant need to be addressed at the system level to try to rule out that the system when processing the data is not changing the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
